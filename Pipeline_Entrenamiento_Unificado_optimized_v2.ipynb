{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78aa3d5c",
   "metadata": {},
   "source": [
    "# Pipeline Unificado de Entrenamiento - Optimizado\n",
    "Este notebook permite seleccionar y entrenar diferentes estrategias de modelos (FeedForward, TabNet, Mixture Density Networks, BayesianNN, Monte Carlo Dropout) sobre los mismos datos, con soporte para GPU y modularidad.\n",
    "\n",
    "- Modularización clara: carga de datos, selección de modelo, entrenamiento, validación y evaluación.\n",
    "- Selección de estrategia mediante parámetro.\n",
    "- Comentarios y documentación en cada bloque.\n",
    "- Importación de módulos desde directorios superiores.\n",
    "\n",
    "**Nota:** Este pipeline reemplaza la lógica redundante de los notebooks de entrenamiento individuales, pero no elimina los originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4c3ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:classes.DataHandler:Configuración de logging inicializada correctamente.\n",
      "INFO:root:Conectado a data/Tronaduras_vs_Sismicidad.db\n",
      "INFO:classes.DataHandler:Columnas objetivo actualizadas: ['Mo_cumulative']\n",
      "INFO:classes.DataHandler:Inicio de la carga de datos.\n",
      "INFO:classes.DataHandler:Tabla Tabla_Unificada cargada correctamente.\n",
      "INFO:classes.DataHandler:Tabla Variables_Description cargada correctamente.\n",
      "INFO:classes.DataHandler:Conexión cerrada.\n",
      "INFO:classes.DataHandler:Datos cargados exitosamente.\n",
      "INFO:classes.DataHandler:Inicio del preprocesamiento de datos.\n",
      "INFO:classes.DataHandler:Variables de entrada procesadas: ['Cobertura Total', 'Cobertura Primario', 'Tronadura_Largo de Perforación (m)', 'Tronadura_N° Tiros', 'Tronadura_N° Tiros Real', 'Tronadura_Kg. de explosivos tronadura', 'Tronadura_Tipo Explosivo', 'Destressing_Se realizó', 'Destressing_N° Tiros', 'Destressing_Kg. de explosivos', 'Destressing_Tipo Explosivo', 'Geotecnicas_UCS (MPa)', 'Geotecnicas_Modulo de Young (GPa)', 'Geotecnicas_Razón Poisson', 'Litología', 'Fallas_Presencia', 'Fallas_Sub-Paralelas', 'Estructura', 'Estructura Crítica', 'Condición de Agua', 'GSI_Puntaje', 'GSI_Blocosidad', 'GSI_Condición Estructuras', 'DTM', 'Blocosidad_Volumen Total', 'Blocosidad_N° Caras', 'Blocosidad_Sumatoria Superficie', 'Blocosidad_Índice Blocosidad', 'Avance_Largo real (m)', 'Avance_Tipo de Explosivo', 'Sobre-excavacion_A (Caja Norte)', 'Sobre-excavacion_B (Acod. Norte)', 'Sobre-excavacion_C (Techo)', 'Sobre-excavacion_D (Acod. Sur)', 'Sobre-excavacion_E (Caja Sur)', 'Sobre-excavacion_% Sobre-Excavación', 'A (Caja Norte)', 'B (Acod. Norte)', 'C (Techo)', 'D (Acod. Sur)', 'E (Caja Sur)', 'Total', 'Coordenadas_Norte (m)', 'Coordenadas_Este (m)', 'Coordenadas_Cota (m)', 'Avance Topográfico (m)', 'Metros Acumulado (m)', 'Área teórica(m2)', '% sobre-excavación', 'Volumen excavado (m3)', 'Tiempo de Ciclo Total (h)', 'Tiempo Ciclo Acumunado (h)', 'Tiempo Tronadura']\n",
      "INFO:classes.DataHandler:Variables target seleccionadas y transformadas: ['Mo_cumulative']\n",
      "INFO:classes.DataHandler:Preprocesamiento de datos completado exitosamente.\n",
      "INFO:classes.DataHandler:Inicio de la normalización de datos.\n",
      "INFO:classes.DataHandler:Datos de entrada normalizados correctamente.\n",
      "INFO:classes.DataHandler:Datos de salida normalizados correctamente.\n",
      "INFO:classes.DataHandler:DataFrame de escalas generado correctamente.\n",
      "INFO:classes.DataHandler:Normalización de datos completada exitosamente.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos leídos desde 'Processed_Data.Tabla_Unificada' y convertidos a DataFrame.\n",
      "✅ Datos leídos desde 'Raw_Data.Variables_Description' y convertidos a DataFrame.\n",
      "🔌 Conexión cerrada manualmente.\n"
     ]
    }
   ],
   "source": [
    "# Configuración de entorno y paths\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))  # Permite importar módulos desde el directorio superior\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from classes.DataHandler import DataHandler\n",
    "# Importar modelos OPTIMIZADOS\n",
    "from classes.FeedForwardNetwork_opt import FeedForwardNetwork_opt\n",
    "from classes.TabNet_opt import TabNetNetwork_opt\n",
    "from classes.MixtureDensityNetworks_opt import MixtureDensityNetworks_opt\n",
    "from classes.BayesianNN_opt import BayesianNN_opt\n",
    "from classes.MonteCarloDropoutNetwork_opt import MonteCarloDropoutNetwork_opt\n",
    "# Para TabNet externo\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import datetime\n",
    "from classes.BaseTrainer_opt import BaseTrainer_opt\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Parámetros globales y de entrenamiento (modificables al inicio)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "TARGETS = ['Mo_cumulative']\n",
    "# FeedForward params:\n",
    "hidden_dim = 528  # Número de neuronas en la(s) capa(s) oculta(s)\n",
    "num_epochs = 1000  # Número de épocas de entrenamiento\n",
    "lr = 0.001  # Tasa de aprendizaje\n",
    "\n",
    "# -----------------------------------\n",
    "# Carga y preprocesamiento de datos\n",
    "# -----------------------------------\n",
    "dh = DataHandler()\n",
    "dh.DEVICE = DEVICE\n",
    "dh.set_targets(TARGETS)\n",
    "table_unified, vars_desc = dh.load_data()\n",
    "inputs, targets = dh.preprocess_data(vars_desc, table_unified)\n",
    "X, y, scales = dh.normalize_data(inputs, targets)\n",
    "# ------\n",
    "# Split con arrays, conversion a tensores SOLO después del split\n",
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "# Conversión a tensores directamente al DEVICE requerido\n",
    "X_train = torch.tensor(X_train_np, dtype=torch.float32).to(DEVICE)\n",
    "X_val   = torch.tensor(X_val_np,   dtype=torch.float32).to(DEVICE)\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.float32).to(DEVICE)\n",
    "y_val   = torch.tensor(y_val_np,   dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b080d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando y evaluando modelo: FeedForward\n",
      "[2025-06-04 09:59:25] 🚀 [FeedForward] Entrenando red...\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 0 📉 train loss: 0.2338 📊 val loss: 0.0214\n",
      "[2025-06-04 09:59:26] 🔄 [FeedForward] [Época 0] 🧠 Pérdida entrenamiento: 0.2338 | Validación: 0.0214\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 4 📉 train loss: 0.0345 📊 val loss: 0.0187\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 11 📉 train loss: 0.0222 📊 val loss: 0.0156\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 12 📉 train loss: 0.0176 📊 val loss: 0.0151\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 20 📉 train loss: 0.0150 📊 val loss: 0.0145\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 27 📉 train loss: 0.0144 📊 val loss: 0.0143\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 40 📉 train loss: 0.0126 📊 val loss: 0.0143\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 44 📉 train loss: 0.0123 📊 val loss: 0.0142\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 45 📉 train loss: 0.0122 📊 val loss: 0.0140\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 46 📉 train loss: 0.0120 📊 val loss: 0.0138\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 47 📉 train loss: 0.0119 📊 val loss: 0.0136\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 48 📉 train loss: 0.0118 📊 val loss: 0.0136\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 49 📉 train loss: 0.0117 📊 val loss: 0.0135\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 50 📉 train loss: 0.0116 📊 val loss: 0.0134\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 51 📉 train loss: 0.0115 📊 val loss: 0.0134\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 54 📉 train loss: 0.0112 📊 val loss: 0.0133\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 55 📉 train loss: 0.0111 📊 val loss: 0.0132\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 56 📉 train loss: 0.0109 📊 val loss: 0.0130\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 57 📉 train loss: 0.0108 📊 val loss: 0.0128\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 58 📉 train loss: 0.0107 📊 val loss: 0.0127\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 59 📉 train loss: 0.0106 📊 val loss: 0.0126\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 60 📉 train loss: 0.0105 📊 val loss: 0.0126\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 61 📉 train loss: 0.0103 📊 val loss: 0.0125\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 62 📉 train loss: 0.0102 📊 val loss: 0.0125\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 63 📉 train loss: 0.0101 📊 val loss: 0.0124\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 64 📉 train loss: 0.0100 📊 val loss: 0.0123\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 65 📉 train loss: 0.0098 📊 val loss: 0.0122\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 66 📉 train loss: 0.0097 📊 val loss: 0.0121\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 67 📉 train loss: 0.0096 📊 val loss: 0.0121\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 68 📉 train loss: 0.0095 📊 val loss: 0.0120\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 69 📉 train loss: 0.0093 📊 val loss: 0.0119\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 70 📉 train loss: 0.0092 📊 val loss: 0.0117\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 71 📉 train loss: 0.0091 📊 val loss: 0.0116\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 72 📉 train loss: 0.0090 📊 val loss: 0.0115\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 73 📉 train loss: 0.0088 📊 val loss: 0.0115\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 75 📉 train loss: 0.0086 📊 val loss: 0.0115\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 76 📉 train loss: 0.0084 📊 val loss: 0.0114\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 77 📉 train loss: 0.0083 📊 val loss: 0.0113\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 78 📉 train loss: 0.0082 📊 val loss: 0.0113\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 79 📉 train loss: 0.0081 📊 val loss: 0.0112\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 80 📉 train loss: 0.0079 📊 val loss: 0.0111\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 81 📉 train loss: 0.0078 📊 val loss: 0.0110\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 82 📉 train loss: 0.0077 📊 val loss: 0.0109\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 83 📉 train loss: 0.0075 📊 val loss: 0.0109\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 84 📉 train loss: 0.0074 📊 val loss: 0.0109\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 85 📉 train loss: 0.0073 📊 val loss: 0.0108\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 86 📉 train loss: 0.0072 📊 val loss: 0.0107\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 87 📉 train loss: 0.0070 📊 val loss: 0.0107\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 88 📉 train loss: 0.0069 📊 val loss: 0.0107\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 89 📉 train loss: 0.0068 📊 val loss: 0.0106\n",
      "[2025-06-04 09:59:26] ✨ [FeedForward] Mejor modelo en época 90 📉 train loss: 0.0067 📊 val loss: 0.0106\n",
      "[2025-06-04 09:59:26] 🔄 [FeedForward] [Época 100] 🧠 Pérdida entrenamiento: 0.0056 | Validación: 0.0107\n",
      "[2025-06-04 09:59:26] 🔄 [FeedForward] [Época 200] 🧠 Pérdida entrenamiento: 0.0011 | Validación: 0.0165\n",
      "[2025-06-04 09:59:27] 🔄 [FeedForward] [Época 300] 🧠 Pérdida entrenamiento: 0.0005 | Validación: 0.0195\n",
      "[2025-06-04 09:59:27] 🔄 [FeedForward] [Época 400] 🧠 Pérdida entrenamiento: 0.0002 | Validación: 0.0217\n",
      "[2025-06-04 09:59:27] 🔄 [FeedForward] [Época 500] 🧠 Pérdida entrenamiento: 0.0001 | Validación: 0.0228\n",
      "[2025-06-04 09:59:27] 🔄 [FeedForward] [Época 600] 🧠 Pérdida entrenamiento: 0.0001 | Validación: 0.0234\n",
      "[2025-06-04 09:59:28] 🔄 [FeedForward] [Época 700] 🧠 Pérdida entrenamiento: 0.0001 | Validación: 0.0240\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m MODEL_TYPE \u001b[38;5;129;01min\u001b[39;00m model_types:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEntrenando y evaluando modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_TYPE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     resultados = \u001b[43mBaseTrainer_opt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_TYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Solo relevante para MDN\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mplot_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Solo relevante para MonteCarloDropout\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Desempaquetar resultados según el modelo\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m MODEL_TYPE \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mFeedForward\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTabNet\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Investigacion_Proyectos\\Proyectos\\Tronaduras y Sismicidad - Teniente\\Python\\classes\\BaseTrainer_opt.py:179\u001b[39m, in \u001b[36mBaseTrainer_opt.run_pipeline\u001b[39m\u001b[34m(model_type, X_train, y_train, X_val, y_val, scales, dh, hidden_dim, n_components, device, lr, num_epochs, save_model, plot_results, dropout_prob, ext)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mFeedForwardNetwork_opt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeedForwardNetwork_opt\n\u001b[32m    178\u001b[39m model = FeedForwardNetwork_opt(input_dim, hidden_dim, device)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_model:\n\u001b[32m    181\u001b[39m     model.save_model(\u001b[33m'\u001b[39m\u001b[33mFeedForward\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Investigacion_Proyectos\\Proyectos\\Tronaduras y Sismicidad - Teniente\\Python\\classes\\FeedForwardNetwork_opt.py:89\u001b[39m, in \u001b[36mFeedForwardNetwork_opt.train_model\u001b[39m\u001b[34m(self, X, y, X_val, y_val, num_epochs, lr)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     88\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.train()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m.squeeze()\n\u001b[32m     90\u001b[39m     loss = criterion(outputs, y.squeeze())\n\u001b[32m     91\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Investigacion_Proyectos\\Proyectos\\Tronaduras y Sismicidad - Teniente\\Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Investigacion_Proyectos\\Proyectos\\Tronaduras y Sismicidad - Teniente\\Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Investigacion_Proyectos\\Proyectos\\Tronaduras y Sismicidad - Teniente\\Python\\classes\\FeedForwardNetwork_opt.py:40\u001b[39m, in \u001b[36mFeedForwardNN_opt.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     x = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.fc2(x))\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Investigacion_Proyectos\\Proyectos\\Tronaduras y Sismicidad - Teniente\\Python\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1704\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1702\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1703\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "model_types = ['FeedForward', 'TabNet', 'MDN', 'BayesianNN', 'MonteCarloDropout']\n",
    "resultados_modelos = {}\n",
    "\n",
    "for MODEL_TYPE in model_types:\n",
    "    print(f\"\\nEntrenando y evaluando modelo: {MODEL_TYPE}\")\n",
    "    resultados = BaseTrainer_opt.run_pipeline(\n",
    "        model_type=MODEL_TYPE,\n",
    "        X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val,\n",
    "        scales=scales, dh=dh,\n",
    "        hidden_dim=hidden_dim,\n",
    "        n_components=5,  # Solo relevante para MDN\n",
    "        device=DEVICE,\n",
    "        lr=lr,\n",
    "        num_epochs=num_epochs,\n",
    "        save_model=True,\n",
    "        plot_results=True,\n",
    "        dropout_prob=0.2  # Solo relevante para MonteCarloDropout\n",
    "    )\n",
    "    \n",
    "    # Desempaquetar resultados según el modelo\n",
    "    if MODEL_TYPE in ['FeedForward', 'TabNet']:\n",
    "        y_train_mo, y_pred_train_mo, y_val_mo, y_pred_val_mo = resultados\n",
    "        std_train = None\n",
    "        std_val = None\n",
    "    elif MODEL_TYPE == 'MDN':\n",
    "        y_train_mo, y_pred_train_mo, y_val_mo, y_pred_val_mo, std_train, std_val = resultados\n",
    "    elif MODEL_TYPE in ['BayesianNN', 'MonteCarloDropout']:\n",
    "        y_train_mo, mean_train_mo, y_val_mo, mean_val_mo, std_train, std_val = resultados\n",
    "        # mean_train_mo y mean_val_mo son las predicciones promedio\n",
    "        y_pred_train_mo = mean_train_mo\n",
    "        y_pred_val_mo = mean_val_mo\n",
    "\n",
    "    resultados_modelos[MODEL_TYPE] = {\n",
    "        'y_train': y_train_mo,\n",
    "        'y_pred_train': y_pred_train_mo,\n",
    "        'y_val': y_val_mo,\n",
    "        'y_pred_val': y_pred_val_mo,\n",
    "        'std_train': std_train,\n",
    "        'std_val': std_val\n",
    "    }\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
